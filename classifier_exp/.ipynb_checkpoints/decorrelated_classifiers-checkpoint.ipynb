{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c6f4e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Graphics\n"
     ]
    }
   ],
   "source": [
    "#HERE TO TEST IDEA FROM LINE CONVERSATION\n",
    "import numpy as np                # import numpy\n",
    "import matplotlib.pyplot as plt   # import matplotlib, a python 2d plotting library\n",
    "from tqdm import tqdm\n",
    "#from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM\n",
    "\n",
    "#import torch packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  print('Running on Graphics')\n",
    "  device=torch.device('cuda:0')\n",
    "else:\n",
    "  device=torch.device('cpu')\n",
    "  print('Running on Processor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b26dfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Conv2d(1,8,3, padding=1)\n",
    "        self.c2 = nn.Conv2d(8,16,3, padding=1)\n",
    "        self.c3 = nn.Conv2d(16,32,3, padding=1)\n",
    "        self.l = nn.Linear(32,10)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.avgpool = nn.AvgPool2d(7)\n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.pool(self.act(self.c1(x)))\n",
    "        self.feat = self.pool(self.act(self.c2(x)))\n",
    "        self.maps = self.act(self.c3(self.feat))\n",
    "        x = self.avgpool(self.maps).flatten(start_dim=1)\n",
    "        x = self.l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0590b7d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Dataset not found. You can use download=True to download it",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-704125b3731e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../mnist_digits/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../mnist_digits/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             raise RuntimeError('Dataset not found.' +\n\u001b[0m\u001b[1;32m     50\u001b[0m                                ' You can use download=True to download it')\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Dataset not found. You can use download=True to download it"
     ]
    }
   ],
   "source": [
    "train_data = MNIST('../mnist_digits/', train=True, download=True,transform=torchvision.transforms.ToTensor())\n",
    "test_data = MNIST('../mnist_digits/', train=False, download=True,transform=torchvision.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7f7373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(optim, train_data, test_data, models, epochs, batch_size):\n",
    "    metrics = []\n",
    "    n = len(test_data)\n",
    "    for i in tqdm(range(epochs)):\n",
    "        for idx, (x, y) in enumerate(DataLoader(train_data, batch_size=batch_size, shuffle=True)):\n",
    "          x = x.to(device)\n",
    "          y = y.to(device)\n",
    "          yhat1 = models[0](x)\n",
    "          yhat2 = models[1](x)\n",
    "          for model in models:\n",
    "              model.zero_grad()\n",
    "          loss = get_loss(y, yhat1, yhat2, models[0], models[1])\n",
    "          loss.backward()\n",
    "          optim.step()\n",
    "        t_acc = torch.zeros(2, dtype=torch.float32)\n",
    "        for idx, (x, y) in enumerate(DataLoader(test_data, batch_size=batch_size)):\n",
    "          x = x.to(device)\n",
    "          y = y.to(device)\n",
    "          for j in range(len(models)):\n",
    "              y_hat = models[j](x)\n",
    "              t_acc[j] = t_acc[j] + torch.sum(torch.argmax(y_hat, dim=1)==y)\n",
    "        t_acc = t_acc/n\n",
    "        metrics.append(t_acc)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563dc09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find mutual residual (proxy for mutual information)\n",
    "def get_R(X,Y):\n",
    "    X = torch.flatten(X, start_dim=1)\n",
    "    Y = torch.flatten(Y, start_dim=1)\n",
    "    #First modify to create nonsingular X:\n",
    "    _,R = torch.linalg.qr(X)\n",
    "    cols = torch.diag(R)\n",
    "    cols = abs(cols/torch.max(cols))>0.0005\n",
    "    X = X[:,cols]\n",
    "\n",
    "    X = torch.cat([X, torch.ones([batch_size,1]).to(device)],dim=1)\n",
    "    Yhat = torch.matmul(torch.matmul(X,torch.linalg.pinv(X)),Y)\n",
    "    #Yhat = torch.matmul(torch.matmul(X,get_pinv(X, q)), Y)\n",
    "    Ehat = Y - Yhat\n",
    "    SSres = torch.sum(torch.square(Ehat))\n",
    "    Ybar = torch.mean(Y, dim=0).unsqueeze(0)\n",
    "    SStot = torch.sum(torch.square(Y-Ybar))\n",
    "    eta = 0.001 #constant for stability\n",
    "    R = 1 - SSres/(SStot+eta)\n",
    "    #print('SSres:{} SStot:{} R:{}'.format(SSres, SStot, R))\n",
    "    return torch.log(SStot+eta)-torch.log(SSres+eta) #R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897edb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda1 = 0.0\n",
    "loss_ce = nn.CrossEntropyLoss()\n",
    "def get_loss(y,yhat1,yhat2, cls1, cls2):\n",
    "    L1 = loss_ce(yhat1,y)\n",
    "    L2 = 0#loss_ce(yhat2,y)\n",
    "    L3 = 0#get_R(cls1.feat, cls2.feat)\n",
    "    print('L1:{} L2:{} L3:{}'.format(L1,L2,L3))\n",
    "    return L1+L2+lambda1*L3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaab150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get2classfiers(epochs):\n",
    "    cls1 = Classifier().to(device)\n",
    "    cls2 = Classifier().to(device)\n",
    "    optimizer = optim.Adam(list(cls1.parameters())+list(cls2.parameters()), lr = 5.0e-3)\n",
    "    loss_ce = nn.CrossEntropyLoss()\n",
    "    models = [cls1, cls2]\n",
    "    metric = train(optimizer, train_data, test_data, models, epochs, batch_size)\n",
    "    print(metric)\n",
    "    return cls1, cls2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0506a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_FGSM(x, y, eta, model):\n",
    "    model.zero_grad()\n",
    "    x.requires_grad = True\n",
    "    y_hat = model(x)\n",
    "    loss = loss_ce(y_hat, y)\n",
    "    loss.backward()\n",
    "    perturbed_x = torch.clamp(x + eta*(x.grad.data).sign(), min=0, max=1.0)\n",
    "    return perturbed_x#, x.grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d972289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transfer(etas):\n",
    "    trans_rate = np.zeros(len(etas))\n",
    "    R2 = np.zeros(len(etas))\n",
    "    cls1, cls2 = get2classfiers(epochs)\n",
    "    for eidx, eta in enumerate(etas):\n",
    "        for x,y in DataLoader(test_data, batch_size, shuffle=True):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            x = gen_FGSM(x,y,eta,cls1)\n",
    "            c1=(torch.argmax(cls1(x), dim=1)==y)\n",
    "            c2=(torch.argmax(cls2(x), dim=1)==y)\n",
    "            adv_tran = torch.sum(~c1 & ~c2)/torch.sum(~c1)\n",
    "            trans_rate[eidx] = trans_rate[eidx] + adv_tran#.detach().cpu().numpy()\n",
    "            R2[eidx] = R2[eidx] + get_R(cls1.feat, cls2.feat)\n",
    "    trans_rate = trans_rate*batch_size/(len(test_data))\n",
    "    R2 = R2*batch_size/(len(test_data))\n",
    "    \n",
    "    return trans_rate, R2, cls1, cls2\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16ed98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "etas = [0.0, 0.05, 0.1, 0.15]\n",
    "epochs=20\n",
    "batch_size=1000\n",
    "trans_rate, R2, cls1, cls2 = get_transfer(etas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96ed11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d167d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('different_cnns', trans_rate_diff, R2_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c54874c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls1.state_dict()['l.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aedc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = cls1.maps[0:5,:,:,:]\n",
    "b = cls1.state_dict()['l.weight'][0,:]\n",
    "b = torch.zeros(32, dtype=torch.float32).to(device)\n",
    "b[7] = 1.0\n",
    "a.shape\n",
    "c = torch.matmul(a.transpose(1,3),b).transpose(1,2)\n",
    "print(c[3,:,:])\n",
    "print(a[3,7,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07293f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Heat Maps\n",
    "import cv2\n",
    "det = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "eta = 0.0\n",
    "x,y = next(iter(DataLoader(test_data, batch_size=100, shuffle=True)))\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "#x = gen_FGSM(x, y, eta, cls1)\n",
    "yhat1 = cls1(x)\n",
    "yhat2 = cls2(x)\n",
    "\n",
    "order = torch.argsort(det(yhat1,y), descending=False)\n",
    "#find best examples\n",
    "x = x[order[0:5]]\n",
    "yhat1 = torch.argmax(cls1(x), dim=1)\n",
    "yhat2 = torch.argmax(cls2(x), dim=1)\n",
    "\n",
    "w1 = cls1.state_dict()['l.weight'][yhat1,:]\n",
    "w2 = cls1.state_dict()['l.weight'][yhat2,:]\n",
    "\n",
    "maps1 = []\n",
    "maps2 = []\n",
    "ims = []\n",
    "\n",
    "for i in range(len(w1)):\n",
    "    map1 = torch.matmul(cls1.maps[i].transpose(0,2),w1[i,:]).transpose(0,1).detach().cpu().numpy()\n",
    "    map2 = torch.matmul(cls2.maps[i].transpose(0,2),w2[i,:]).transpose(0,1).detach().cpu().numpy()\n",
    "    map1 = cv2.resize(map1,(28,28))\n",
    "    map1 = cv2.applyColorMap(np.uint8(map1*255/np.max(map1)), cv2.COLORMAP_JET)\n",
    "    map2 = cv2.resize(map2,(28,28))\n",
    "    map2 = cv2.applyColorMap(np.uint8(map2*255/np.max(map2)), cv2.COLORMAP_JET)\n",
    "    maps1.append(map1)\n",
    "    maps2.append(map2)\n",
    "    \n",
    "    ims.append(cv2.cvtColor(np.uint8(255*torch.squeeze(x[i]).detach().cpu().numpy()), cv2.COLOR_GRAY2RGB))\n",
    "\n",
    "opacity=.85\n",
    "fig, ax = plt.subplots(3,len(ims))\n",
    "for i in range(len(ims)):\n",
    "    ax[0,i].imshow(ims[i])\n",
    "    ax[1,i].imshow(np.float32(opacity*maps1[i]+ims[i])/np.max(opacity*maps1[i]+ims[i]))\n",
    "    ax[2,i].imshow(np.float32(opacity*maps2[i]+ims[i])/np.max(opacity*maps2[i]+ims[i]))\n",
    "    for s in ax[:,i]:\n",
    "        s.axes.xaxis.set_ticks([])\n",
    "        s.axes.yaxis.set_ticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee79a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Heat Maps\n",
    "import cv2\n",
    "det = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "eta = 0.0\n",
    "x,y = next(iter(DataLoader(test_data, batch_size=5, shuffle=True)))\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "#x = gen_FGSM(x, y, eta, cls1)\n",
    "yhat1 = cls1(x)\n",
    "yhat2 = cls2(x)\n",
    "\n",
    "#order = torch.argsort(det(yhat1,y), descending=False)\n",
    "#find best examples\n",
    "#x = x[order[0:5]]\n",
    "cls1.eval()\n",
    "cls2.eval()\n",
    "yhat1 = torch.argmax(cls1(x), dim=1)\n",
    "yhat2 = torch.argmax(cls2(x), dim=1)\n",
    "\n",
    "w1 = cls1.state_dict()['l.weight'][yhat1,:]\n",
    "w2 = cls1.state_dict()['l.weight'][yhat2,:]\n",
    "\n",
    "maps1 = []\n",
    "maps2 = []\n",
    "ims = []\n",
    "\n",
    "for i in range(len(w1)):\n",
    "    map1 = torch.matmul(cls1.maps[i].transpose(0,2),w1[i,:]).transpose(0,1).detach().cpu().numpy()\n",
    "    map2 = torch.matmul(cls2.maps[i].transpose(0,2),w2[i,:]).transpose(0,1).detach().cpu().numpy()\n",
    "    map1 = cv2.resize(map1,(28,28))\n",
    "    map1 = cv2.applyColorMap(np.uint8(map1*255/np.max(map1)), cv2.COLORMAP_JET)\n",
    "    map2 = cv2.resize(map2,(28,28))\n",
    "    map2 = cv2.applyColorMap(np.uint8(map2*255/np.max(map2)), cv2.COLORMAP_JET)\n",
    "    maps1.append(map1)\n",
    "    maps2.append(map2)\n",
    "    \n",
    "    ims.append(cv2.cvtColor(np.uint8(255*torch.squeeze(x[i]).detach().cpu().numpy()), cv2.COLOR_GRAY2RGB))\n",
    "\n",
    "opacity=.85\n",
    "fig, ax = plt.subplots(3,len(ims))\n",
    "for i in range(len(ims)):\n",
    "    ax[0,i].imshow(ims[i])\n",
    "    ax[1,i].imshow(np.float32(opacity*maps1[i]+ims[i])/np.max(opacity*maps1[i]+ims[i]))\n",
    "    ax[2,i].imshow(np.float32(opacity*maps2[i]+ims[i])/np.max(opacity*maps2[i]+ims[i]))\n",
    "    for s in ax[:,i]:\n",
    "        s.axes.xaxis.set_ticks([])\n",
    "        s.axes.yaxis.set_ticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9248d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('heat_map.jpg', format='jpg', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1140e94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "x1 = decoder(bn1(encoder(x_adv[ind[0:n]]))).detach().cpu().numpy()\n",
    "x2 = decoder(bn2(encoder(x_adv[ind[0:n]]))).detach().cpu().numpy()\n",
    "x_n = x_adv[ind[0:n]].detach().cpu().numpy()\n",
    "x_gt = x[ind[0:n]].detach().cpu().numpy()\n",
    "\n",
    "\n",
    "    \n",
    "fig, ax = plt.subplots(4,n)\n",
    "for i in range(len(ax[0])):\n",
    "    ax[0,i].imshow(np.squeeze(x_gt[i]))\n",
    "    ax[1,i].imshow(np.squeeze(x_n[i]))\n",
    "    ax[2,i].imshow(np.squeeze(x1[i]))\n",
    "    ax[3,i].imshow(np.squeeze(x2[i]))\n",
    "    for s in ax[:,i]:\n",
    "        s.axes.xaxis.set_ticks([])\n",
    "        s.axes.yaxis.set_ticks([])\n",
    "\n",
    "#ax[0,0].set_ylabel('GT')\n",
    "#ax[1,0].set_ylabel('Recon 1')\n",
    "#ax[2,0].set_ylabel('Recon 2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
