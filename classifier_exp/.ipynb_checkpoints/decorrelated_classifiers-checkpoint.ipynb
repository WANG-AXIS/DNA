{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c6f4e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Graphics\n"
     ]
    }
   ],
   "source": [
    "#HERE TO TEST IDEA FROM LINE CONVERSATION\n",
    "import numpy as np                # import numpy\n",
    "import matplotlib.pyplot as plt   # import matplotlib, a python 2d plotting library\n",
    "from tqdm import tqdm\n",
    "\n",
    "#import torch packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  print('Running on Graphics')\n",
    "  device=torch.device('cuda:0')\n",
    "else:\n",
    "  device=torch.device('cpu')\n",
    "  print('Running on Processor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b26dfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Conv2d(1,8,3, padding=1)\n",
    "        self.c2 = nn.Conv2d(8,16,3, padding=1)\n",
    "        self.c3 = nn.Conv2d(16,32,3, padding=1)\n",
    "        self.l = nn.Linear(32,10)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.avgpool = nn.AvgPool2d(7)\n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.pool(self.act(self.c1(x)))\n",
    "        self.feat = self.pool(self.act(self.c2(x)))\n",
    "        self.maps = self.act(self.c3(self.feat))\n",
    "        x = self.avgpool(self.maps).flatten(start_dim=1)\n",
    "        x = self.l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd7f7373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(optim, train_data, test_data, models, epochs, batch_size):\n",
    "    metrics = []\n",
    "    n = len(test_data)\n",
    "    for i in tqdm(range(epochs)):\n",
    "        for idx, (x, y) in enumerate(DataLoader(train_data, batch_size=batch_size, shuffle=True)):\n",
    "          x = x.to(device)\n",
    "          y = y.to(device)\n",
    "          yhat1 = models[0](x)\n",
    "          yhat2 = models[1](x)\n",
    "          for model in models:\n",
    "              model.zero_grad()\n",
    "          loss = get_loss(y, yhat1, yhat2, models[0], models[1])\n",
    "          loss.backward()\n",
    "          optim.step()\n",
    "        t_acc = torch.zeros(2, dtype=torch.float32)\n",
    "        for idx, (x, y) in enumerate(DataLoader(test_data, batch_size=batch_size)):\n",
    "          x = x.to(device)\n",
    "          y = y.to(device)\n",
    "          for j in range(len(models)):\n",
    "              y_hat = models[j](x)\n",
    "              t_acc[j] = t_acc[j] + torch.sum(torch.argmax(y_hat, dim=1)==y)\n",
    "        t_acc = t_acc/n\n",
    "        metrics.append(t_acc)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "563dc09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find mutual residual (proxy for mutual information)\n",
    "def get_R(X,Y):\n",
    "    X = torch.flatten(X, start_dim=1)\n",
    "    Y = torch.flatten(Y, start_dim=1)\n",
    "    #First modify to create nonsingular X:\n",
    "    _,R = torch.linalg.qr(X)\n",
    "    cols = torch.diag(R)\n",
    "    cols = abs(cols/torch.max(cols))>0.0005\n",
    "    X = X[:,cols]\n",
    "\n",
    "    X = torch.cat([X, torch.ones([batch_size,1]).to(device)],dim=1)\n",
    "    Yhat = torch.matmul(torch.matmul(X,torch.linalg.pinv(X)),Y)\n",
    "    #Yhat = torch.matmul(torch.matmul(X,get_pinv(X, q)), Y)\n",
    "    Ehat = Y - Yhat\n",
    "    SSres = torch.sum(torch.square(Ehat))\n",
    "    Ybar = torch.mean(Y, dim=0).unsqueeze(0)\n",
    "    SStot = torch.sum(torch.square(Y-Ybar))\n",
    "    eta = 0.001 #constant for stability\n",
    "    R = 1 - SSres/(SStot+eta)\n",
    "    #print('SSres:{} SStot:{} R:{}'.format(SSres, SStot, R))\n",
    "    return torch.log(SStot+eta)-torch.log(SSres+eta) #R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "897edb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda1 = 0.05\n",
    "loss_ce = nn.CrossEntropyLoss()\n",
    "def get_loss(y,yhat1,yhat2, cls1, cls2):\n",
    "    L1 = loss_ce(yhat1,y)\n",
    "    L2 = loss_ce(yhat2,y)\n",
    "    L3 = get_R(cls1.feat, cls2.feat)\n",
    "    #print('L1:{} L2:{} L3:{}'.format(L1,L2,L3))\n",
    "    return L1+L2+lambda1*L3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aaab150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get2classfiers(epochs):\n",
    "    cls1 = Classifier().to(device)\n",
    "    cls2 = Classifier().to(device)\n",
    "    optimizer = optim.Adam(list(cls1.parameters())+list(cls2.parameters()), lr = 5.0e-3)\n",
    "    loss_ce = nn.CrossEntropyLoss()\n",
    "    models = [cls1, cls2]\n",
    "    metric = train(optimizer, train_data, test_data, models, epochs, batch_size)\n",
    "    print('Model 1 Accuracy:{}%   Model 2 Accuracy:{}%'.format(metric[-1][0],metric[-1][1]))\n",
    "    return cls1, cls2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0506a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_FGSM(x, y, eta, model):\n",
    "    model.zero_grad()\n",
    "    x.requires_grad = True\n",
    "    y_hat = model(x)\n",
    "    loss = loss_ce(y_hat, y)\n",
    "    loss.backward()\n",
    "    perturbed_x = torch.clamp(x + eta*(x.grad.data).sign(), min=0, max=1.0)\n",
    "    return perturbed_x#, x.grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d972289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transfer(cls1, cls2, etas):\n",
    "    trans_rate = np.zeros(len(etas))\n",
    "    R2 = np.zeros(len(etas))\n",
    "    for eidx, eta in enumerate(etas):\n",
    "        for x,y in DataLoader(test_data, batch_size, shuffle=True):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            x = gen_FGSM(x,y,eta,cls1)\n",
    "            c1=(torch.argmax(cls1(x), dim=1)==y)\n",
    "            c2=(torch.argmax(cls2(x), dim=1)==y)\n",
    "            adv_tran = torch.sum(~c1 & ~c2)/torch.sum(~c1)\n",
    "            trans_rate[eidx] = trans_rate[eidx] + adv_tran#.detach().cpu().numpy()\n",
    "            R2[eidx] = R2[eidx] + get_R(cls1.feat, cls2.feat)\n",
    "    trans_rate = trans_rate*batch_size/(len(test_data))\n",
    "    R2 = R2*batch_size/(len(test_data))\n",
    "    \n",
    "    return trans_rate, R2\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f533abe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_transfer(source_model, target_model, data, attack, epsilon):\n",
    "    data_loader = DataLoader(data, batch_size=1000, shuffle=False)\n",
    "    adv_sample_count = 0.0\n",
    "    adv_transfer_count = 0.0\n",
    "    for x,y in data_loader:\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        x = attack(x,y,epsilon, source_model)\n",
    "        yhat_s = torch.argmax(source_model(x), dim=1)\n",
    "        yhat_t = torch.argmax(target_model(x), dim=1)\n",
    "        adv_s, adv_t = yhat_s!=y, yhat_t!=y\n",
    "        adv_sample_count = adv_sample_count + torch.sum(adv_s)\n",
    "        adv_transfer_count = adv_transfer_count + torch.sum(adv_s & adv_t)\n",
    "    transfer_rate = adv_transfer_count/adv_sample_count\n",
    "    return transfer_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0590b7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "train_data = MNIST('../mnist_digits/', train=True, download=True,transform=torchvision.transforms.ToTensor())\n",
    "test_data = MNIST('../mnist_digits/', train=False, download=True,transform=torchvision.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f16ed98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:11<00:00,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Accuracy:0.9502000212669373%   Model 2 Accuracy:0.9635000228881836%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "get_transfer() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0fe8a9dc8577>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcls1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget2classfiers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrans_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_transfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: get_transfer() takes 1 positional argument but 3 were given"
     ]
    }
   ],
   "source": [
    "etas = [0.0, 0.05, 0.1, 0.15]\n",
    "epochs=20\n",
    "batch_size=1000\n",
    "\n",
    "\n",
    "\n",
    "cls1, cls2 = get2classfiers(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a96ed11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.41688304, 0.15965211, 0.23606322, 0.54795227])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_rate, R2 = get_transfer(cls1, cls2, etas)\n",
    "trans_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c1e8ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5644, device='cuda:0')\n",
      "tensor(0.3532, device='cuda:0')\n",
      "tensor(0.5076, device='cuda:0')\n",
      "tensor(0.6968, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for eta in etas:\n",
    "    print(find_transfer(cls2, cls1, test_data, gen_FGSM, eta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d167d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savez('transfer_rate_decorrelated_cnns', trans_rate, R2_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87b53905",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'saved_models/CNN/test'\n",
    "torch.save(cls1.state_dict(), save_dir+'1')\n",
    "torch.save(cls2.state_dict(), save_dir+'2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
