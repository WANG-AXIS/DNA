{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Graphics\n"
     ]
    }
   ],
   "source": [
    "import numpy as np                # import numpy\n",
    "import matplotlib.pyplot as plt   # import matplotlib, a python 2d plotting library\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "#import torch packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  print('Running on Graphics')\n",
    "  device=torch.device('cuda:0')\n",
    "else:\n",
    "  device=torch.device('cpu')\n",
    "  print('Running on Processor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bottleneck(nn.Module):\n",
    "  def __init__(self, in_size, bn_size, act=nn.ReLU()):\n",
    "    super().__init__()\n",
    "    self.L1 = nn.Linear(in_size, bn_size)\n",
    "    self.L2 = nn.Linear(bn_size, in_size)\n",
    "    self.act = act\n",
    "\n",
    "  def forward(self, x):\n",
    "    self.bn = self.act(self.L1(x))\n",
    "    x = self.act(self.L2(self.bn))\n",
    "    return x\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "  def __init__(self, in_size, bn_size):\n",
    "    super().__init__()\n",
    "    self.enc = nn.Sequential(\n",
    "        nn.Linear(28*28, 100),\n",
    "        nn.ReLU(),nn.Linear(100,in_size),\n",
    "        nn.ReLU())\n",
    "        \n",
    "  def forward(self, x):\n",
    "    x = torch.flatten(x, start_dim=1)\n",
    "    x = self.enc(x)\n",
    "    return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "  def __init__(self, in_size, bn_size):\n",
    "    super().__init__()\n",
    "    self.dec = nn.Sequential(nn.Linear(in_size, 100), nn.ReLU(),\n",
    "        nn.Linear(100, 28*28),\n",
    "        nn.Sigmoid())\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.dec(x)\n",
    "    return x.reshape(-1,1,28,28)\n",
    "\n",
    "class DNA(nn.Module):\n",
    "    def __init__(self, in_size, bn_size):\n",
    "        super().__init__()\n",
    "        self.enc = Encoder(in_size, bn_size)\n",
    "        self.dec = Decoder(in_size, bn_size)\n",
    "        self.bn1 = bottleneck(in_size, bn_size)\n",
    "        self.bn2 = bottleneck(in_size, bn_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.enc(x)\n",
    "        r1 = self.dec(self.bn1(x))\n",
    "        r2 = self.dec(self.bn2(x))\n",
    "        return r1, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    def __init__(self, in_size, bn_size):\n",
    "        super().__init__()\n",
    "        self.enc = Encoder(in_size, bn_size)\n",
    "        self.dec = Decoder(in_size, bn_size)\n",
    "        self.bn = bottleneck(in_size, bn_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.enc(x)\n",
    "        r1 = self.dec(self.bn(x))\n",
    "        return r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "  def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c = nn.Sequential(\n",
    "            nn.Conv2d(1,8,3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(8,16,3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16,32,3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(start_dim=1),\n",
    "            nn.Linear(288,10))\n",
    "        \n",
    "  def forward(self, x):\n",
    "        self.out = self.c(x)\n",
    "        return self.out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MNIST('../../mnist_digits/', train=True, download=True,transform=torchvision.transforms.ToTensor())\n",
    "test_data = MNIST('../../mnist_digits/', train=False, download=True,transform=torchvision.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_PGD(x_nat, y, epsilon, loss_f, models, k=40, a=3/255):\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "    y = y.to(device)\n",
    "    x_nat = x_nat.to(device)\n",
    "    x = x_nat + (2*epsilon*torch.rand(x_nat.shape) - epsilon).to(device)\n",
    "    x = torch.clamp(x, 0, 1)\n",
    "    for i in range(k):\n",
    "        x.requires_grad = True\n",
    "        for model in models:\n",
    "            model.zero_grad()\n",
    "        loss = loss_f(x,y)\n",
    "        loss.backward()\n",
    "        x = x + a*x.grad.data.sign()\n",
    "        x = torch.clamp(x, 0, 1)\n",
    "        perturb = torch.clamp(x-x_nat, -epsilon, epsilon)\n",
    "        x = (x_nat + perturb).detach()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_FGSM(x, y, epsilon, loss_f, models):\n",
    "    for model in models:\n",
    "        model.zero_grad()\n",
    "    x.requires_grad = True\n",
    "    loss = loss_f(x,y)\n",
    "    loss.backward()\n",
    "    perturbed_x = torch.clamp(x + epsilon*(x.grad.data).sign(), min=0, max=1.0)\n",
    "    return perturbed_x.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_ce = nn.CrossEntropyLoss()\n",
    "def eval_AE(auto, cls, epsilons, attack_function, label, DN):\n",
    "    results = []\n",
    "    if DN:\n",
    "        loss_f = lambda x,y: loss_ce(cls(auto(x)[0]),y)**2 + loss_ce(cls(auto(x)[1]),y)**2\n",
    "        a_type = 'DNA (dual)'\n",
    "    else:\n",
    "        loss_f = lambda x,y: loss_ce(cls(auto(x)),y)\n",
    "        a_type = 'AE'\n",
    "    for epsilon in epsilons:\n",
    "        total_correct = 0.0\n",
    "        for x,y in DataLoader(test_data, batch_size=500):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            if epsilon != 0.0:\n",
    "                x = attack_function(x, y, epsilon, loss_f, [auto, cls])\n",
    "            xhat = auto(x)\n",
    "            if DN:\n",
    "                yhat1 = torch.argmax(cls(xhat[0]), dim=1)\n",
    "                yhat2 = torch.argmax(cls(xhat[1]), dim=1)\n",
    "                total_correct = total_correct + torch.sum((yhat1==y) | (yhat2==y)).detach().cpu().numpy()\n",
    "\n",
    "            else:\n",
    "                yhat1 = torch.argmax(cls(xhat), dim=1)\n",
    "                total_correct = total_correct + torch.sum(yhat1==y).detach().cpu().numpy()\n",
    "        acc = total_correct/len(test_data)\n",
    "        results.append([a_type, label, epsilon, acc])\n",
    "    if DN:\n",
    "        loss_f = [lambda x,y: loss_ce(cls(auto(x)[0]),y), lambda x,y: loss_ce(cls(auto(x)[1]),y)]\n",
    "        a_type = 'DNA (single)'\n",
    "        for epsilon in epsilons:\n",
    "            total_correct = 0.0\n",
    "            for x,y in DataLoader(test_data, batch_size=500):\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                for i in range(2):\n",
    "                    if epsilon != 0:\n",
    "                        x_adv = attack_function(x, y, epsilon, loss_f[i], [auto, cls])\n",
    "                    else:\n",
    "                        x_adv = x\n",
    "                    xhat = auto(x_adv)\n",
    "                    yhat1 = torch.argmax(cls(xhat[0]), dim=1)\n",
    "                    yhat2 = torch.argmax(cls(xhat[1]), dim=1)\n",
    "                    total_correct = total_correct + torch.sum((yhat1==y) | (yhat2==y)).detach().cpu().numpy()\n",
    "            acc = total_correct/(2*len(test_data))\n",
    "            results.append([a_type, label, epsilon, acc])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the Adversarial Tests\n",
    "epsilons = [0.0, 0.05, 0.1, 0.15]\n",
    "dna = AE(in_size, bn_size).to(device)\n",
    "cls = Classifier().to(device)\n",
    "dna.load_state_dict(torch.load('models/ae'))\n",
    "cls.load_state_dict(torch.load('models/cls_ae'))\n",
    "\n",
    "results = eval_AE(dna, cls, epsilons, gen_FGSM, 'FGSM', DN=False)\n",
    "results.extend(eval_AE(dna, cls, epsilons, gen_PGD, 'PGD', DN=False))\n",
    "\n",
    "dna = DNA(in_size, bn_size).to(device)\n",
    "cls = Classifier().to(device)\n",
    "dna.load_state_dict(torch.load('models/dna'))\n",
    "cls.load_state_dict(torch.load('models/cls_dna'))\n",
    "\n",
    "results.extend(eval_AE(dna, cls, epsilons, gen_FGSM, 'FGSM', DN=True))\n",
    "results.extend(eval_AE(dna, cls, epsilons, gen_PGD, 'PGD', DN=True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results in dataframe\n",
    "results_table = pd.DataFrame(results, columns=['Model', 'Attack', r'$\\epsilon$', 'Accuracy'])\n",
    "results_table.columns = ['Model', 'Attack', r'$\\epsilon$', 'Accuracy']\n",
    "results_table['Accuracy'] = results_table['Accuracy']*100\n",
    "results_table.to_pickle(\"results.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_table = results_table[results_table.Model != 'DNA (single)']\n",
    "results_table['Model'] = results_table['Model'].replace('DNA (dual)', 'DNA')\n",
    "sns.set_theme()\n",
    "fig, ax = plt.subplots(1,2, figsize=(15,5))\n",
    "\n",
    "sns.lineplot(ax=ax[0], data=results_table[results_table.Attack == 'FGSM'], x=r'$\\epsilon$', y='Accuracy', hue='Model', palette='Blues_d')\n",
    "ax[0].set_ylim(0,100)\n",
    "ax[0].set_xlabel(r'Attack Magnitude ($\\epsilon$; FGSM)')\n",
    "ax[0].set_ylabel('Accuracy (%)')\n",
    "\n",
    "sns.lineplot(ax=ax[1], data=results_table[results_table.Attack == 'PGD'], x=r'$\\epsilon$', y='Accuracy', hue='Model', palette='Blues_d')\n",
    "ax[1].set_ylim(0,100)\n",
    "ax[1].set_xlabel(r'Attack Magnitude ($\\epsilon$; PGD)')\n",
    "ax[1].set_ylabel('Accuracy (%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('line_plot.jpg', bbox_inches = 'tight', pad_inches = 0, format='jpg', dpi=600)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
